## Описание проекта

Сделал на библиотеке pika. 
Попытался максимально распараллелить с помощью Threading (concurrent.futures.ThreadPoolExecutor()), процессы можно использовать для параллельного запуска нескольких инстансов.
Как указано в задании, сервис обрабатывает одновременно до 10 сообщений.
Сообщения поступают в очередь reports_input, репорты поступают либо напрямую (если указаны заголовки reply_to, correlation_to), либо в очередь reports_output, либо ответа нет, если не указаны заголовки и в сообщении не передано correlation_id.

Проблемы:
    
    - Данные из data.json выгружаются в глобальныq DataFrame при запуске программы, по хорошему это конечно в MongoDB убрать.
    
    - Возможно, если стоит задача на статичную обработку 10-ти сообщений, можно сделать 10 процессов для обработки по 1 сообщению через multiproccesing
    
    - Нет никакой модели данных для pandas DataFrame'а, с которым работает сервис
    
    - Возможно для оптимизации как и работы, так и реализации, с точки зрения кода, можно было использовать aio_pika, вместо pika
    
    - Нет тестирования

## Запуск

Сначала нужно занести в папку **static** файл **data.json** (данные для агрегации). 

`pip install -r requirements.txt`

В проекте присутствует docker-compose для разворачивания в docker. Но так как данные выгружаются в оперативку, то для докера должно быть выделенно достаточное кол-во памяти (у меня сейчас доступна только Windows, так что я в местном docker клиенте не смог снять ограничение на 7 Гб)

Другой вариант запустить rabbitMQ: `docker run -d -p 15672:15672 -p 5672:5672 rabbitmq:management` и запустить main.py вручную. (запуск, из-за выгрузки дата фрейма, будет длится 1-2 минуты)

Сообщения отправлять можно через веб-сервис в очередь repots_input.

Протестировать "эксклюзивный" ответ на сообщения, можно с помощью скрипта в test.py
